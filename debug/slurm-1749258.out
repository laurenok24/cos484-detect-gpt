Saving results to absolute path: /scratch/network/tb19/cos484-detect-gpt/tmp_results/main/gpt2-xl-t5-3b-temp/2023-04-18-22-21-05-770314-fp32-0.3-1-xsum-500
Using cache dir /scratch/network/tb19/.cache
Loading BASE model gpt2-xl...
Loading mask filling model t5-3b...
MOVING BASE MODEL TO GPU...Using the latest cached version of the module from /home/tb19/.cache/huggingface/modules/datasets_modules/datasets/xsum/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71 (last modified on Tue Apr 18 20:13:01 2023) since it couldn't be found locally at xsum., or remotely on the Hugging Face Hub.
Found cached dataset xsum (/scratch/network/tb19/.cache/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71)
Token indices sequence length is longer than the specified maximum sequence length for this model (853 > 512). Running this sequence through the model will result in indexing errors
DONE (1.24s)
Loading dataset xsum...
Total number of samples: 1829
Average number of words: 306.9710224166211
Generating samples for batch 0 of 10
Generating samples for batch 1 of 10
Generating samples for batch 2 of 10
Generating samples for batch 3 of 10
Generating samples for batch 4 of 10
Generating samples for batch 5 of 10
Generating samples for batch 6 of 10
Generating samples for batch 7 of 10
Generating samples for batch 8 of 10
Generating samples for batch 9 of 10
Writing raw data to tmp_results/main/gpt2-xl-t5-3b-temp/2023-04-18-22-21-05-770314-fp32-0.3-1-xsum-500/raw_data.json
Computing likelihood criterion:   0%|          | 0/10 [00:00<?, ?it/s]Computing likelihood criterion:  10%|█         | 1/10 [00:06<00:57,  6.38s/it]Computing likelihood criterion:  20%|██        | 2/10 [00:12<00:49,  6.24s/it]Computing likelihood criterion:  30%|███       | 3/10 [00:18<00:43,  6.18s/it]Computing likelihood criterion:  40%|████      | 4/10 [00:24<00:36,  6.13s/it]Computing likelihood criterion:  50%|█████     | 5/10 [00:30<00:30,  6.14s/it]Computing likelihood criterion:  60%|██████    | 6/10 [00:37<00:24,  6.14s/it]Computing likelihood criterion:  70%|███████   | 7/10 [00:43<00:18,  6.13s/it]Computing likelihood criterion:  80%|████████  | 8/10 [00:49<00:12,  6.13s/it]Computing likelihood criterion:  90%|█████████ | 9/10 [00:55<00:06,  6.12s/it]Computing likelihood criterion: 100%|██████████| 10/10 [01:01<00:00,  6.12s/it]Computing likelihood criterion: 100%|██████████| 10/10 [01:01<00:00,  6.15s/it]
likelihood_threshold ROC AUC: 0.8791599999999999, PR AUC: 0.8496150223780717
Computing rank criterion:   0%|          | 0/10 [00:00<?, ?it/s]Computing rank criterion:  10%|█         | 1/10 [00:06<01:00,  6.67s/it]Computing rank criterion:  20%|██        | 2/10 [00:13<00:51,  6.47s/it]Computing rank criterion:  30%|███       | 3/10 [00:19<00:44,  6.40s/it]Computing rank criterion:  40%|████      | 4/10 [00:25<00:38,  6.43s/it]Computing rank criterion:  50%|█████     | 5/10 [00:32<00:31,  6.40s/it]Computing rank criterion:  60%|██████    | 6/10 [00:38<00:25,  6.38s/it]Computing rank criterion:  70%|███████   | 7/10 [00:44<00:19,  6.34s/it]Computing rank criterion:  80%|████████  | 8/10 [00:51<00:12,  6.33s/it]Computing rank criterion:  90%|█████████ | 9/10 [00:57<00:06,  6.32s/it]Computing rank criterion: 100%|██████████| 10/10 [01:03<00:00,  6.32s/it]Computing rank criterion: 100%|██████████| 10/10 [01:03<00:00,  6.37s/it]
rank_threshold ROC AUC: 0.790524, PR AUC: 0.8091126933929396
Computing log_rank criterion:   0%|          | 0/10 [00:00<?, ?it/s]Computing log_rank criterion:  10%|█         | 1/10 [00:06<00:57,  6.44s/it]Computing log_rank criterion:  20%|██        | 2/10 [00:12<00:51,  6.38s/it]Computing log_rank criterion:  30%|███       | 3/10 [00:19<00:44,  6.35s/it]Computing log_rank criterion:  40%|████      | 4/10 [00:25<00:37,  6.31s/it]Computing log_rank criterion:  50%|█████     | 5/10 [00:31<00:31,  6.32s/it]Computing log_rank criterion:  60%|██████    | 6/10 [00:38<00:25,  6.33s/it]Computing log_rank criterion:  70%|███████   | 7/10 [00:44<00:18,  6.31s/it]Computing log_rank criterion:  80%|████████  | 8/10 [00:50<00:12,  6.31s/it]Computing log_rank criterion:  90%|█████████ | 9/10 [00:56<00:06,  6.31s/it]Computing log_rank criterion: 100%|██████████| 10/10 [01:03<00:00,  6.31s/it]Computing log_rank criterion: 100%|██████████| 10/10 [01:03<00:00,  6.32s/it]
log_rank_threshold ROC AUC: 0.908568, PR AUC: 0.887564520929254
Computing entropy criterion:   0%|          | 0/10 [00:00<?, ?it/s]Computing entropy criterion:  10%|█         | 1/10 [00:06<00:55,  6.17s/it]Computing entropy criterion:  20%|██        | 2/10 [00:12<00:49,  6.18s/it]Computing entropy criterion:  30%|███       | 3/10 [00:18<00:43,  6.17s/it]Computing entropy criterion:  40%|████      | 4/10 [00:24<00:36,  6.14s/it]Computing entropy criterion:  50%|█████     | 5/10 [00:30<00:30,  6.16s/it]Computing entropy criterion:  60%|██████    | 6/10 [00:36<00:24,  6.16s/it]Computing entropy criterion:  70%|███████   | 7/10 [00:43<00:18,  6.15s/it]Computing entropy criterion:  80%|████████  | 8/10 [00:49<00:12,  6.15s/it]Computing entropy criterion:  90%|█████████ | 9/10 [00:55<00:06,  6.15s/it]Computing entropy criterion: 100%|██████████| 10/10 [01:01<00:00,  6.15s/it]Computing entropy criterion: 100%|██████████| 10/10 [01:01<00:00,  6.16s/it]
entropy_threshold ROC AUC: 0.5641800000000001, PR AUC: 0.5568465027086535
Beginning supervised evaluation with roberta-base-openai-detector...
Traceback (most recent call last):
  File "/scratch/network/tb19/cos484-detect-gpt/run.py", line 886, in <module>
    baseline_outputs.append(eval_supervised(data, model='roberta-base-openai-detector'))
  File "/scratch/network/tb19/cos484-detect-gpt/run.py", line 693, in eval_supervised
    detector = transformers.AutoModelForSequenceClassification.from_pretrained(model, cache_dir=cache_dir).to(DEVICE)
  File "/home/tb19/.conda/envs/pytorch/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 434, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
  File "/home/tb19/.conda/envs/pytorch/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 776, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/tb19/.conda/envs/pytorch/lib/python3.10/site-packages/transformers/configuration_utils.py", line 559, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/tb19/.conda/envs/pytorch/lib/python3.10/site-packages/transformers/configuration_utils.py", line 614, in _get_config_dict
    resolved_config_file = cached_file(
  File "/home/tb19/.conda/envs/pytorch/lib/python3.10/site-packages/transformers/utils/hub.py", line 409, in cached_file
    resolved_file = hf_hub_download(
  File "/home/tb19/.conda/envs/pytorch/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1136, in hf_hub_download
    with open(ref_path) as f:
FileNotFoundError: [Errno 2] No such file or directory: '/scratch/network/tb19/.cache/models--roberta-base-openai-detector/refs/main'
